{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting details on weight initialization https://pouannes.github.io/blog/initialization/\n",
    "\n",
    "Use Kaiming method \n",
    "\n",
    "\"The Kaiming paper accordingly suggests to initialize the weights of layer l with a zero-mean Gaussian distribution with a standard deviation of sqrt(s/Nl) , and null biases.\"\n",
    "\n",
    "Nl is the number of neurons in layer l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(number):\n",
    "    return max(0, number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, activation=0, inNeurons=[], outNeurons=[], weights=[], bias=0):\n",
    "        self.inNeurons = inNeurons\n",
    "        self.outNeurons = outNeurons\n",
    "        self.activation = activation\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "        \n",
    "    def addIn(self, n, weight):\n",
    "        self.inNeurons.append(n)\n",
    "        self.weights.append(weight)\n",
    "        \n",
    "    def addOut(self, neuron):\n",
    "        self.outNeurons.append(neuron)\n",
    "    \n",
    "    def getActivation(self):\n",
    "        return self.activation\n",
    "    \n",
    "    def setActivation(self, a):\n",
    "        self.activation = a\n",
    "        return a\n",
    "\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self, neurons=[], generate=True, size=0):\n",
    "        self.neurons = neurons.copy()\n",
    "        print(\"Initializing Layer\")\n",
    "        if generate:\n",
    "            for i in range(size):\n",
    "                self.neurons.append(Neuron())\n",
    "        print(\"Created layer of size %d\" % len(self.neurons))\n",
    "        self.upLayer = None\n",
    "        self.downLayer = None\n",
    "        self.weights = None\n",
    "        self.activations = np.array(list(map(Neuron.getActivation, self.neurons)))\n",
    "    \n",
    "    def setActivations(self, actList):\n",
    "        \"\"\"\n",
    "        Sets activations of neurons in layer to actList\n",
    "        \"\"\"\n",
    "        if len(actList) == len(self.activations):\n",
    "            for i in range(len(self.neurons)):\n",
    "                self.neurons[i].setActivation(actList[i])\n",
    "            self.activations = actList\n",
    "        else:\n",
    "            raise Exception(\"Invalid activation list length\")\n",
    "                \n",
    "    \n",
    "    def getActivations(self):\n",
    "        \"\"\"\n",
    "        Returns activation of neurons in layer\n",
    "        \"\"\"\n",
    "        return self.activations\n",
    "    \n",
    "    def downstreamConnect(self, l, weights=None):\n",
    "        \"\"\"\n",
    "        Connects neuron layer \"l\" to self \n",
    "        Connection is such that \"l\" is downstream in the neural network\n",
    "        Unless specified, initializes weights randomly within Kaiming distribution\n",
    "        layer1.upstreamConnect(layer2) is equivalent to layer2.downstreamConnect(layer1)\n",
    "        IMPORTANT NOTE: WEIGHT MATRIX MIGHT NOT PROPERLY FOLLOW KAIMING\n",
    "        INSTEAD THEY SAMPLE RANDOMLY FROM A GAUSSIAN DISTRIBUTION WITH VARIANCE DETERMINED BY KAIMING\n",
    "        MAY CAUSE PROBLEMS WITH SMALL LAYERS, POSSIBLY NEEDS FIX LATER\n",
    "        \"\"\"\n",
    "        upLayerNeurons = self.neurons\n",
    "        downLayerNeurons = l.neurons\n",
    "        \n",
    "        if not weights:\n",
    "            #  Create random weight initialization matrix\n",
    "            #  Weights are picked randomly from gaussian of mean=0 and variance according to Kaiming\n",
    "            weightVariance = np.sqrt(2/len(upLayerNeurons))\n",
    "            weights = np.random.normal(scale=weightVariance, size=(len(downLayerNeurons), len(upLayerNeurons)))\n",
    "            print(\"Created %d by %d weight matrix\" % weights.shape)\n",
    "            \n",
    "        for d in range(len(downLayerNeurons)):\n",
    "            for u in range(len(upLayerNeurons)):\n",
    "                upLayerNeurons[u].addOut(downLayerNeurons[d])\n",
    "                downLayerNeurons[d].addIn(upLayerNeurons[u], weights[d, u])\n",
    "        \n",
    "        l.weights = weights   \n",
    "        l.upLayer = self\n",
    "        self.downLayer = l\n",
    "        \n",
    "        return weights\n",
    "                \n",
    "    def upstreamConnect(self, l):\n",
    "        \"\"\"\n",
    "        Connects neuron layer \"l\" to self \n",
    "        Connection is such that \"l\" is upstream in the neural network\n",
    "        layer1.upstreamConnect(layer2) is equivalent to layer2.downstreamConnect(layer1)\n",
    "        \"\"\"\n",
    "        for n in l.neurons:\n",
    "            for m in self.neurons:\n",
    "                m.addIn(n)\n",
    "                n.addOut(m)\n",
    "    \n",
    "    def update(self):\n",
    "        \"\"\"\n",
    "        Updates neuron activations based on weight matrix and activations of upstream layer\n",
    "        \"\"\"\n",
    "        weightedSum = np.matmul(self.weights, self.upLayer.getActivations())\n",
    "        newActivations = np.array(list(map(relu, weightedSum)))\n",
    "        self.setActivations(newActivations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Layer\n",
      "Created layer of size 10\n",
      "layer1 activations: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Initializing Layer\n",
      "Created layer of size 5\n",
      "Created 5 by 10 weight matrix\n",
      "None\n",
      "[[-1.47612657e-01  7.00266436e-02 -3.86857952e-01  2.44231871e-01\n",
      "  -5.11581105e-01  6.29678468e-01  9.69320771e-02 -1.14095097e-01\n",
      "   8.70955712e-02  5.25006423e-01]\n",
      " [-3.27654066e-02  8.35222746e-01 -4.33882671e-01  2.30364963e-01\n",
      "  -6.07749374e-01 -2.08042401e-01 -3.43093467e-01  3.83549804e-02\n",
      "   4.54905837e-01 -5.47256141e-01]\n",
      " [-1.02174289e-01  8.32014127e-01 -5.62639431e-01 -7.09635658e-01\n",
      "  -2.57103406e-01  5.42895129e-01 -2.55470158e-01 -1.14638487e-01\n",
      "   4.75743832e-02  1.30422402e-02]\n",
      " [-7.68870245e-01  6.21537055e-01 -2.20485065e-01 -3.37433382e-01\n",
      "  -7.35873928e-01  2.19016727e-01  5.47458948e-01  7.02717176e-01\n",
      "  -2.33518773e-01  3.25378269e-01]\n",
      " [ 3.57918967e-01  3.60815909e-01  3.49489333e-01  2.82763751e-01\n",
      "   7.51037453e-01 -2.74775861e-01  3.91986022e-01  1.04634436e-01\n",
      "  -6.26162139e-04  1.35229715e-01]]\n",
      "layer2 activations: [0 0 0 0 0]\n",
      "layer2 activations: [6.33582343 0.         0.         6.58388286 7.83477166]\n"
     ]
    }
   ],
   "source": [
    "layer1 = Layer(size=10)\n",
    "layer1.setActivations(list(range(10)))\n",
    "print(\"layer1 activations: %s\" % layer1.activations)\n",
    "layer2 = Layer(size=5)\n",
    "\n",
    "w = layer1.downstreamConnect(layer2)\n",
    "print(layer1.weights)\n",
    "print(layer2.weights)\n",
    "print(\"layer2 activations: %s\" % layer2.activations)\n",
    "layer2.update()\n",
    "print(\"layer2 activations: %s\" % layer2.activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<__main__.Neuron object at 0x000002174CFB1EC8>, <__main__.Neuron object at 0x000002174CFB1AC8>, <__main__.Neuron object at 0x000002174CFB19C8>, <__main__.Neuron object at 0x000002174CFB14C8>, <__main__.Neuron object at 0x000002174CFB1E48>, <__main__.Neuron object at 0x000002174CFB1608>, <__main__.Neuron object at 0x000002174CFB1248>, <__main__.Neuron object at 0x000002174CFB11C8>, <__main__.Neuron object at 0x000002174CFB1388>, <__main__.Neuron object at 0x000002174CFB1B08>]\n",
      "[<__main__.Neuron object at 0x000002174CFB1288>, <__main__.Neuron object at 0x000002174CFB1348>, <__main__.Neuron object at 0x000002174CFB1E88>, <__main__.Neuron object at 0x000002174CFB1148>, <__main__.Neuron object at 0x000002174CFB1088>]\n"
     ]
    }
   ],
   "source": [
    "print(layer1.neurons)\n",
    "print(layer2.neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 5)\n"
     ]
    }
   ],
   "source": [
    "print(w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
