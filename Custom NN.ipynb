{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting details on weight initialization https://pouannes.github.io/blog/initialization/\n",
    "\n",
    "Use Kaiming method \n",
    "\n",
    "\"The Kaiming paper accordingly suggests to initialize the weights of layer l with a zero-mean Gaussian distribution with a standard deviation of sqrt(s/Nl) , and null biases.\"\n",
    "\n",
    "Nl is the number of neurons in layer l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(number):\n",
    "    \"\"\"\n",
    "    Returns the ReLU of a number\n",
    "    ReLU function is 0 for all negative inputs, and f(x) = x for all x >= 0\n",
    "    \"\"\"\n",
    "    return max(0, number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    \"\"\"\n",
    "    Neuron class for neural network\n",
    "    Each neuron is a node in the network\n",
    "    Can be organized into layers with Layer class\n",
    "    Each Neuron has a list of Neurons coming in (the upstream neurons in the network)\n",
    "    and a list of Neurons going out (the downstream neurons in the network)\n",
    "    The weights correspond to the list of input Neurons\n",
    "    ex. a Neuron with 5 upstream neurons will have 5 weights, one for each input\n",
    "    Bias determines a Neurons tendency to be off/on\n",
    "    \"\"\"\n",
    "    def __init__(self, activation=0.5, inNeurons=[], outNeurons=[], weights=[], bias=0):\n",
    "        \"\"\"\n",
    "        Constructor for Neuron class\n",
    "        \"\"\"\n",
    "        self.inNeurons = inNeurons\n",
    "        self.outNeurons = outNeurons\n",
    "        self.activation = activation\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "        \n",
    "    def addIn(self, n, weight):\n",
    "        \"\"\"\n",
    "        Adds input neuron with provided weight\n",
    "        Used in Layer class to connect Layers\n",
    "        \"\"\"\n",
    "        self.inNeurons.append(n)\n",
    "        self.weights.append(weight)\n",
    "        \n",
    "    def addOut(self, neuron):\n",
    "        \"\"\"\n",
    "        Adds output neuron\n",
    "        Used in Layer class to connect Layers\n",
    "        \"\"\"\n",
    "        self.outNeurons.append(neuron)\n",
    "    \n",
    "    def getActivation(self):\n",
    "        \"\"\"\n",
    "        Returns activation of Neuron\n",
    "        \"\"\"\n",
    "        return self.activation\n",
    "    \n",
    "    def setActivation(self, a):\n",
    "        \"\"\"\n",
    "        Sets activation of Neuron to a\n",
    "        Returns a\n",
    "        \"\"\"\n",
    "        self.activation = a\n",
    "        return a\n",
    "    \n",
    "    def getBias(self):\n",
    "        \"\"\"\n",
    "        Returns bias of Neuron\n",
    "        \"\"\"\n",
    "        return self.bias\n",
    "    \n",
    "    def setBias(self, b):\n",
    "        \"\"\"\n",
    "        Sets bias of Neuron to b\n",
    "        Returns b\n",
    "        \"\"\"\n",
    "        self.bias = b\n",
    "        return b\n",
    "\n",
    "\n",
    "class Layer:\n",
    "    \"\"\"\n",
    "    Layer class for neural network\n",
    "    Layers are collections of neurons\n",
    "    Layers can be linked together to form networks\n",
    "    \"\"\"\n",
    "    def __init__(self, neurons=[], generate=True, size=0):\n",
    "        \"\"\"\n",
    "        Constructor for Layer class\n",
    "        Can input a list of neurons to build layer, or randomly generate\n",
    "        neurons for layer of desired size\n",
    "        \"\"\"\n",
    "        self.neurons = neurons.copy()\n",
    "        print(\"Initializing Layer\")\n",
    "        \n",
    "        #  Generates the neurons for the layer\n",
    "        if generate and len(self.neurons) == 0:\n",
    "            for i in range(size):\n",
    "                self.neurons.append(Neuron())\n",
    "        \n",
    "        print(\"Created layer of size %d\" % len(self.neurons))\n",
    "        \n",
    "        #  Initializes attributes\n",
    "        self.size = size\n",
    "        self.upLayer = None\n",
    "        self.downLayer = None\n",
    "        self.weights = None\n",
    "        self.weightsSet = False\n",
    "        self.desiredOut = []\n",
    "        self.z = []  #  Pre-ReLU activations\n",
    "        \n",
    "        #  Records activations and biases of neurons in layer\n",
    "        self.biases = np.array(list(map(Neuron.getBias, self.neurons)))\n",
    "        self.activations = np.array(list(map(Neuron.getActivation, self.neurons)))\n",
    "    \n",
    "    def setActivations(self, actList):\n",
    "        \"\"\"\n",
    "        Sets activations of neurons in layer to actList\n",
    "        \"\"\"\n",
    "        #  Checks to ensure provided activation list is the appropriate size\n",
    "        if len(actList) == self.size:\n",
    "            for i in range(self.size):\n",
    "                self.neurons[i].setActivation(actList[i])\n",
    "            self.activations = actList\n",
    "        else:\n",
    "            raise Exception(\"Invalid activation list length\")\n",
    "                \n",
    "    \n",
    "    def getActivations(self):\n",
    "        \"\"\"\n",
    "        Returns activations of Neurons in Layer\n",
    "        \"\"\"\n",
    "        return self.activations\n",
    "    \n",
    "    def getBiases(self):\n",
    "        \"\"\"\n",
    "        Returns biases of Neurons in Layer\n",
    "        \"\"\"\n",
    "        return self.biases\n",
    "    \n",
    "    def getSize(self):\n",
    "        \"\"\"\n",
    "        Returns number of Neurons in Layer\n",
    "        \"\"\"\n",
    "        return self.size\n",
    "    \n",
    "    def downstreamConnect(self, down, weights=None):\n",
    "        \"\"\"\n",
    "        Connects neuron layer \"down\" to self \n",
    "        Connection is such that \"down\" is downstream in the neural network\n",
    "        Unless specified, weight matrix is initialized randomly within Kaiming distribution\n",
    "        layer1.upstreamConnect(layer2) is equivalent to layer2.downstreamConnect(layer1)\n",
    "        IMPORTANT NOTE: WEIGHT MATRIX MIGHT NOT PROPERLY FOLLOW KAIMING\n",
    "        INSTEAD THEY SAMPLE RANDOMLY FROM A GAUSSIAN DISTRIBUTION WITH VARIANCE DETERMINED BY KAIMING\n",
    "        MAY CAUSE PROBLEMS WITH SMALL LAYERS, POSSIBLY NEEDS FIX LATER\n",
    "        \"\"\"\n",
    "        upLayerNeurons = self.neurons\n",
    "        downLayerNeurons = down.neurons\n",
    "        \n",
    "        if not weights:\n",
    "            #  Create random weight initialization matrix\n",
    "            #  Weights are picked randomly from gaussian of mean=0 and variance according to Kaiming\n",
    "            weightVariance = np.sqrt(2/len(upLayerNeurons))\n",
    "            weights = np.random.normal(scale=weightVariance, size=(down.getSize(), self.getSize()))\n",
    "            print(\"Created %d by %d weight matrix\" % weights.shape)\n",
    "            down.weightsSet = True\n",
    "            \n",
    "        for d in range(down.getSize()):\n",
    "            for u in range(self.getSize()):\n",
    "                #  Connect all Neurons between the Layers\n",
    "                #  Set weights of Neurons in downstream Layer\n",
    "                upLayerNeurons[u].addOut(downLayerNeurons[d])\n",
    "                downLayerNeurons[d].addIn(upLayerNeurons[u], weights[d, u])\n",
    "        \n",
    "        #  Set weight matrix of downstream Layer and mark up/downstream connections\n",
    "        down.weights = weights  #  This should be a method like updateWeights(), might be useful later\n",
    "        down.upLayer = self\n",
    "        self.downLayer = down\n",
    "        self.update()\n",
    "        \n",
    "        return weights\n",
    "    \n",
    "    def upstreamConnect(self, up):\n",
    "        \"\"\"\n",
    "        IMPLEMENTATION INCOMPLETE\n",
    "        Connects neuron layer \"up\" to self \n",
    "        Connection is such that \"up\" is upstream in the neural network\n",
    "        layer1.upstreamConnect(layer2) is equivalent to layer2.downstreamConnect(layer1)\n",
    "        \"\"\"\n",
    "    \n",
    "    def updateZ(self):\n",
    "        \"\"\"\n",
    "        Updates Neuron pre-ReLU activations based on weight matrix, \n",
    "        biases and activations of upstream Layer\n",
    "        \"\"\"\n",
    "        #  Only update if weights had been set\n",
    "        if self.weightsSet:\n",
    "            #  Update pre-ReLU activations\n",
    "            self.z = np.matmul(self.weights, self.upLayer.getActivations())\n",
    "            self.z = np.subtract(self.z, self.biases)\n",
    "            \n",
    "    def update(self):\n",
    "        \"\"\"\n",
    "        Updates Neuron activations based on weight matrix, biases and activations of upstream Layer\n",
    "        \"\"\"\n",
    "        #  Only update if weights had been set\n",
    "        if self.weightsSet:\n",
    "            #  Update pre-ReLU activations\n",
    "            self.z = np.matmul(self.weights, self.upLayer.getActivations())\n",
    "            self.z = np.subtract(self.z, self.biases)\n",
    "            #  Update activations\n",
    "            newActivations = np.array(list(map(relu, self.z)))\n",
    "            self.setActivations(newActivations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "    \"\"\"\n",
    "    Neural Network class\n",
    "    A NN consists of Neuron Layers, connected in a linear manner\n",
    "    End Layers act as data input and output\n",
    "    Middle Layers each have upstream and downstream connections\n",
    "    and serve as NN's hidden Layers\n",
    "    \"\"\"\n",
    "    def __init__(self, numLayers, layerSizes):\n",
    "        \"\"\"\n",
    "        Constructor for NN class\n",
    "        numLayers is an integer that determines the number of Layers in the NN\n",
    "        layerSizes is a list or tuple of length numLayers that determines the\n",
    "        number of Neurons in each layer, with layerSizes[0] being the size of the input layer\n",
    "        \"\"\"\n",
    "        self.numLayers = numLayers\n",
    "        self.layerSizes = layerSizes\n",
    "        print(\"Creating Neural Network with %d layers\" % numLayers)\n",
    "        self.layers = []\n",
    "        self.desiredOut = []\n",
    "        self.lRate = 0.0002\n",
    "        \n",
    "        #  Create layers and connect them\n",
    "        for i in range(numLayers):\n",
    "            self.layers.append(Layer(size=layerSizes[i]))\n",
    "            if i > 0:\n",
    "                #  No downstream connection for the last layer\n",
    "                self.layers[i-1].downstreamConnect(self.layers[i])\n",
    "            self.layers[i].updateZ()\n",
    "        print(\"Neural Network Initialized\")\n",
    "        \n",
    "    def inputData(self, dataIn, dataOut):\n",
    "        \"\"\"\n",
    "        Sets input layer activations to dataIn if data is the proper size\n",
    "        Saves dataOut as desired output if data is the proper size\n",
    "        Otherwise raises Exception\n",
    "        \"\"\"\n",
    "        if self.layers[0].getSize() == len(dataIn) and self.layers[-1].getSize() == len(dataOut):\n",
    "            self.layers[0].setActivations(dataIn)\n",
    "            self.desiredOut = dataOut\n",
    "            self.layers[-1].desiredOut = dataOut\n",
    "        else:\n",
    "            raise Exception(\"Invalid data size\")\n",
    "            \n",
    "    def getCost(self):\n",
    "        \"\"\"\n",
    "        Returns resulting cost of current NN configuration based on desired output\n",
    "        \"\"\"\n",
    "        return np.sum(np.square(np.subtract(self.layers[-1].getActivations(), self.layers[-1].desiredOut)))\n",
    "    \n",
    "    def backprop(layer):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        #  dCost/dWeights(L) = dz(L)/dw(L) * da(L)/dz(L) * dC/da(L)\n",
    "        #  z(L) is pre-ReLU activations, a(L) is activations of Layer L\n",
    "        size = layer.getSize()\n",
    "        upSize = layer.upLayer.getSize()\n",
    "        gradient = np.ndarray(upSize)\n",
    "        upAct = layer.upLayer.getActivations()\n",
    "        act = layer.getActivations()\n",
    "        actZPartial = np.where(layer.z >= 0, 1, 0)\n",
    "        #  Iterate through each activation in the previous layer, calculating the partial of the cost function\n",
    "        #  with respect to each one\n",
    "        for k in range(upSize):\n",
    "            costPartial = 0\n",
    "            for j in range(size):\n",
    "                costPartial += 2 * (act[j] - layer.desiredOut[j]) * layer.weights[j][k]\n",
    "            gradient[k] = costPartial\n",
    "        \n",
    "        #print(\"current activation: %s\" % layer.upLayer.getActivations())\n",
    "        #print(\"activation gradient: %s\" % gradient)\n",
    "        layer.upLayer.desiredOut = np.subtract(layer.upLayer.getActivations(), gradient)\n",
    "        #print(\"new desired activation: %s\" % layer.upLayer.desiredOut)\n",
    "    \n",
    "    def gradientDescentWeights(self, layer):\n",
    "        \"\"\"\n",
    "        Finds the vector for gradient descent of weights of a Layer and subtracts \n",
    "        this vector from that Layer's weights\n",
    "        Returns the vector\n",
    "        \"\"\"\n",
    "        #  dCost/dWeights(L) = dz(L)/dw(L) * da(L)/dz(L) * dC/da(L)\n",
    "        #  z(L) is pre-ReLU activations, a(L) is activations of Layer L\n",
    "        size = layer.getSize()\n",
    "        upSize = layer.upLayer.getSize()\n",
    "        gradient = np.ndarray(shape=(size, upSize))\n",
    "        upAct = layer.upLayer.getActivations()\n",
    "        act = layer.getActivations()\n",
    "        actZPartial = np.where(layer.z >= 0, 1, 0)\n",
    "        \n",
    "        #  Iterate through each weight, calculating the partial of the cost function\n",
    "        #  with respect to each one\n",
    "        for k in range(upSize):\n",
    "            for j in range(size):\n",
    "                gradient[j][k] = self.lRate * 2 * (act[j] - layer.desiredOut[j]) * upAct[k] * actZPartial[j]\n",
    "                \n",
    "#         print(\"current weights: %s\" % layer.weights)\n",
    "#         print(\"weight gradient: %s\" % gradient)\n",
    "        layer.weights = np.subtract(layer.weights, gradient)\n",
    "#         print(\"new weights: %s\" % layer.weights)\n",
    "        \n",
    "    def gradientDescentBiases(layer):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        #  dCost/dBiases(L) = dz(L)/db(L) * da(L)/dz(L) * dC/da(L)\n",
    "        #  z(L) is pre-ReLU activations, a(L) is activations of Layer L\n",
    "        actZPartial = np.where(layer.z >= 0, 1, 0)\n",
    "        size = layer.getSize()\n",
    "        gradient = np.ndarray(size)\n",
    "        \n",
    "        for j in range(size):\n",
    "            act = layer.getActivations()\n",
    "            gradient[j] = 2 * (act[j] - layer.desiredOut[j]) * actZPartial[j]\n",
    "        #print(\"bias gradient: %s\" % gradient)\n",
    "        layer.biases = np.subtract(layer.biases, gradient)\n",
    "        #print(\"new biases: %s\" % layer.biases)\n",
    "    \n",
    "    def showStructure(self):\n",
    "        \"\"\"\n",
    "        Prints out the number of layers in the NN\n",
    "        Prints out the sizes of each layer\n",
    "        \"\"\"\n",
    "        print(\"The network is contains %d layers\" % self.numLayers)\n",
    "        print(\"The layer sizes are %s\" % self.layerSizes)\n",
    "        \n",
    "    def updateActivations(self):\n",
    "        \"\"\"\n",
    "        Updates activations of all Neurons in all Layers in NN according\n",
    "        to their weights and the activations of their upstream Layer\n",
    "        \"\"\"\n",
    "        #  Input layer is skipped, as it has no upstream layer\n",
    "        for layer in self.layers[1:]:\n",
    "            layer.update()\n",
    "            \n",
    "    def showActivations(self):\n",
    "        \"\"\"\n",
    "        Displays activations of each Layer of the NN\n",
    "        \"\"\"\n",
    "        for i in range(self.numLayers):\n",
    "            print(self.layers[i].getActivations())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Neural Network with 3 layers\n",
      "Initializing Layer\n",
      "Created layer of size 100\n",
      "Initializing Layer\n",
      "Created layer of size 150\n",
      "Created 150 by 100 weight matrix\n",
      "Initializing Layer\n",
      "Created layer of size 100\n",
      "Created 100 by 150 weight matrix\n",
      "Neural Network Initialized\n",
      "The network is contains 3 layers\n",
      "The layer sizes are [100, 150, 100]\n",
      "[0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5\n",
      " 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5\n",
      " 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5\n",
      " 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5\n",
      " 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5\n",
      " 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "[0.         0.14851926 1.42446971 0.17107507 1.48490998 0.\n",
      " 0.         0.83780285 0.76572864 0.37205165 0.         0.\n",
      " 1.70187275 0.         0.88307633 0.40209216 0.         0.01973994\n",
      " 0.896831   0.         0.53596979 0.66051062 0.         0.01403707\n",
      " 0.38740254 0.67360326 0.         0.         0.         0.\n",
      " 0.0572981  0.         0.         0.25912204 0.         0.14281042\n",
      " 0.0342966  0.         0.         0.2693628  0.         0.\n",
      " 0.         0.666535   1.04738832 0.         0.         0.\n",
      " 0.21551921 0.         0.23597438 0.         0.05958077 0.\n",
      " 0.74578751 0.         1.55881454 0.         0.21020622 0.\n",
      " 0.         0.         0.         0.20909345 0.         0.76999978\n",
      " 0.         0.         0.2629665  0.         0.         0.68941522\n",
      " 0.         0.         0.         0.08905512 0.         0.58879307\n",
      " 0.         0.80995005 0.52822907 0.98655452 0.42384537 0.54314256\n",
      " 0.         0.84852674 0.         0.         0.37387206 0.12662974\n",
      " 0.         0.2977914  0.26703039 0.4676397  0.         1.02368774\n",
      " 0.61915925 0.19732567 0.33189491 0.         0.81270895 0.\n",
      " 0.33159758 0.         0.         0.         0.         0.\n",
      " 0.55599062 0.35978499 0.         0.43452987 1.3577488  0.\n",
      " 0.6366846  0.93793025 0.         0.         0.         0.73046956\n",
      " 0.         0.         0.52818381 0.26162053 0.70838137 0.\n",
      " 0.         0.         0.83724285 0.         0.         0.55090426\n",
      " 0.         0.         0.         0.92670335 0.         0.56622943\n",
      " 0.         0.         0.21518794 0.83226411 0.80790727 0.10118127\n",
      " 0.         0.         0.83395345 0.98898158 0.19888871 0.52567986]\n",
      "[0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5\n",
      " 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5\n",
      " 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5\n",
      " 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5\n",
      " 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5\n",
      " 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n"
     ]
    }
   ],
   "source": [
    "nn = NN(4, [100, 200, 200, 100])\n",
    "nn.showStructure()\n",
    "nn.showActivations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20dc1cd59c8>]"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn.lRate = 0.005\n",
    "batchSize = 100\n",
    "epochs = 10\n",
    "avgs = []\n",
    "for j in range(epochs):\n",
    "    totalCost = 0\n",
    "    for i in range(batchSize):\n",
    "        dataIn = np.random.uniform(size=100)\n",
    "        dataOut = dataIn\n",
    "        nn.inputData(dataIn, dataOut)\n",
    "        nn.updateActivations()\n",
    "        nn.gradientDescentWeights(nn.layers[-1])\n",
    "        NN.backprop(nn.layers[-1])\n",
    "        nn.gradientDescentWeights(nn.layers[2])\n",
    "        NN.backprop(nn.layers[2])\n",
    "        nn.gradientDescentWeights(nn.layers[1])\n",
    "        #print(\"cost: %s\" % nn.getCost())\n",
    "        totalCost += nn.getCost()\n",
    "    avgs.append(totalCost/batchSize)\n",
    "plt.plot(list(range(epochs)), avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23152661 0.16490844 0.70825391 0.82504532 0.88186114 0.91900104\n",
      " 0.87127716 0.94130916 0.90530067 0.26342053 0.51127645 0.99036172\n",
      " 0.62393329 0.63088554 0.14366774 0.64621208 0.6882334  0.24106153\n",
      " 0.50971242 0.84928101 0.88373899 0.56823902 0.2650873  0.33129322\n",
      " 0.91604626 0.88732532 0.3995242  0.64047747 0.7538864  0.0132713\n",
      " 0.14782014 0.04762488 0.93942435 0.06292629 0.00313194 0.57069143\n",
      " 0.80164099 0.04943121 0.87626117 0.77129915 0.44048571 0.58877019\n",
      " 0.07186639 0.92395598 0.60335728 0.81955587 0.44251054 0.7785534\n",
      " 0.19396277 0.32624415 0.04249976 0.16384518 0.2715746  0.71887282\n",
      " 0.94618429 0.0789304  0.22980754 0.7047195  0.37071399 0.94080459\n",
      " 0.43144534 0.33254312 0.19509161 0.93332398 0.41890519 0.43878621\n",
      " 0.20204652 0.99609043 0.55165363 0.60850041 0.87046983 0.22627932\n",
      " 0.31702682 0.12460775 0.19885357 0.06704909 0.62362359 0.22703587\n",
      " 0.15172039 0.31316514 0.02645047 0.93928421 0.24520381 0.46874406\n",
      " 0.09033198 0.59533073 0.29964126 0.42685099 0.49336149 0.97280652\n",
      " 0.51946476 0.34641578 0.73798807 0.35878663 0.9132139  0.20886088\n",
      " 0.25427258 0.04657643 0.44270331 0.15647609]\n",
      "[4.86798945 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         5.856803   2.67702818 0.         0.         0.\n",
      " 0.         4.49301315 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         2.73218881 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.21079098 0.\n",
      " 0.         0.         4.35862222 0.         0.         0.12186808\n",
      " 0.         0.         0.         0.         0.         3.38275656\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         2.01412442\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         5.6325974  0.         0.\n",
      " 3.93333491 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         2.46661142 0.         0.\n",
      " 0.         0.         0.         4.83109123 0.         0.        ]\n",
      "[0.40330095 0.35903501 0.20735614 0.50981872 0.49429241 0.51462052\n",
      " 0.43374686 0.53230429 0.61653899 0.41956894 0.41231367 0.63395555\n",
      " 0.53976348 0.42569806 0.52677858 0.4304328  0.51313112 0.36840094\n",
      " 0.47741174 0.47680412 0.40722937 0.3897359  0.49645682 0.47882019\n",
      " 0.56807094 0.67387663 0.41185104 0.43366233 0.41082192 0.65636737\n",
      " 0.36090546 0.38928993 0.48033925 0.50331257 0.52087558 0.42668103\n",
      " 0.44935563 0.38785169 0.58145622 0.51336932 0.48151354 0.53404129\n",
      " 0.45337865 0.42753982 0.36783028 0.65195016 0.37018035 0.35135232\n",
      " 0.35948405 0.62360674 0.46426875 0.49956794 0.42156531 0.36438586\n",
      " 0.56143676 0.38713608 0.44666189 0.49456656 0.4223269  0.52798704\n",
      " 0.4378713  0.49341627 0.43135917 0.48573744 0.36614956 0.38923407\n",
      " 0.48402552 0.35595868 0.45606616 0.45133824 0.49853063 0.56484808\n",
      " 0.409214   0.41631524 0.39845304 0.39720884 0.50472063 0.56281549\n",
      " 0.3843264  0.46193184 0.46943418 0.46630938 0.43245176 0.53281439\n",
      " 0.66386424 0.38394032 0.44936308 0.45552045 0.32056478 0.48280914\n",
      " 0.43811044 0.3142744  0.54287906 0.44218587 0.53698144 0.40796176\n",
      " 0.48343722 0.58578814 0.55981923 0.51365911]\n"
     ]
    }
   ],
   "source": [
    "dataIn = np.random.uniform(size=100)\n",
    "dataOut = dataIn\n",
    "nn.inputData(dataIn, dataOut)\n",
    "nn.updateActivations()\n",
    "nn.showActivations()\n",
    "nn.gradientDescentWeights(nn.layers[-1])\n",
    "#NN.updateDesiredActivationsUp(nn.layers[-1])\n",
    "#NN.gradientDescentWeights(nn.layers[1])\n",
    "#NN.gradientDescentBiases(nn.layers|[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.85763284e-01, -9.53067618e-02,  1.38168028e-02,\n",
       "         1.21340044e-01,  6.49441225e-02,  5.36655354e-02,\n",
       "        -4.94809432e-02, -1.37181201e-02, -6.22587014e-02,\n",
       "        -1.00176610e-02,  2.21071862e-02,  3.74124980e-02,\n",
       "        -5.53929429e-02,  4.38559896e-02,  1.30377362e-01,\n",
       "        -4.10302011e-04, -1.50522282e-01, -2.79499991e-02,\n",
       "        -6.15028127e-02, -2.93604213e-02, -7.43626967e-02,\n",
       "        -6.02290926e-02,  6.71950191e-02,  4.78110802e-02,\n",
       "         4.83217029e-02],\n",
       "       [ 4.41621770e-02,  1.02252894e+00, -4.69512351e-02,\n",
       "         2.76336735e-02, -3.29459967e-03, -1.12963103e-01,\n",
       "        -3.03899246e-02, -1.21436529e-01,  2.88504869e-02,\n",
       "         7.70789562e-03, -1.47701803e-02,  1.59503795e-01,\n",
       "         7.51927586e-02,  4.96191326e-02, -2.67707108e-02,\n",
       "        -6.64294041e-02,  5.26784551e-02, -1.87020110e-01,\n",
       "         8.34004490e-02,  3.75442185e-02, -6.93452092e-02,\n",
       "         2.29531669e-02,  1.07338930e-01,  1.98157020e-02,\n",
       "         5.29166563e-02],\n",
       "       [-3.30656360e-02,  8.87084236e-02,  1.16879950e+00,\n",
       "         6.18069548e-02, -5.66571545e-02,  9.48429323e-02,\n",
       "         3.28545075e-02,  3.89141048e-02, -1.07471659e-03,\n",
       "        -7.31082220e-02, -2.63069753e-02,  3.03279104e-02,\n",
       "        -5.52480779e-02, -5.09545339e-03, -9.40707182e-02,\n",
       "        -1.43700426e-01, -6.41046507e-02, -4.35953352e-02,\n",
       "        -4.66931943e-02,  1.10397855e-01,  7.60283942e-02,\n",
       "         1.54886761e-02, -8.83612007e-02, -1.36704094e-01,\n",
       "        -4.58219341e-02],\n",
       "       [ 1.23462194e-02,  3.91145323e-02, -1.08093162e-02,\n",
       "         9.84060559e-01, -1.81675620e-02,  3.70730785e-02,\n",
       "        -8.87426621e-03,  3.04941512e-02,  5.45376445e-02,\n",
       "        -8.01356908e-02, -7.85673562e-02, -1.20276528e-02,\n",
       "         2.40459404e-02, -1.26948254e-01, -9.27687303e-02,\n",
       "         7.44366392e-02, -7.66722019e-02,  8.59063722e-02,\n",
       "         2.47343167e-02, -2.39111319e-02,  7.56826372e-02,\n",
       "         5.64519403e-02, -9.38190237e-02, -4.56544945e-02,\n",
       "         3.45915700e-02],\n",
       "       [ 4.03325064e-02,  1.44009936e-02,  3.47182267e-02,\n",
       "         2.15693685e-02,  1.13785306e+00, -9.80531695e-02,\n",
       "        -1.14622448e-01, -1.80939874e-02,  7.16353281e-02,\n",
       "        -4.74933912e-02,  2.56296708e-02, -1.60357379e-02,\n",
       "        -5.13411011e-02, -4.25991709e-03, -1.33356564e-01,\n",
       "        -6.24600601e-02, -5.66943027e-02,  7.61330619e-02,\n",
       "        -1.00667260e-01,  7.59050611e-02,  4.26353934e-02,\n",
       "         1.21486734e-01, -6.63406218e-02, -5.77840577e-02,\n",
       "        -4.02230479e-02],\n",
       "       [ 7.05609205e-03,  1.40449068e-01,  5.13510936e-02,\n",
       "        -2.33025799e-02, -5.78922521e-02,  9.70015362e-01,\n",
       "        -3.27471697e-02, -4.98566600e-02, -6.48366666e-02,\n",
       "        -3.73465859e-02, -4.32929818e-02, -2.91730160e-02,\n",
       "         5.99104238e-02, -5.39336642e-02,  3.66561286e-02,\n",
       "        -1.07326454e-01, -1.23036866e-01, -6.85863391e-02,\n",
       "         1.35645895e-01, -2.50104972e-02, -2.31791056e-02,\n",
       "        -4.06771167e-02,  3.06426605e-02,  2.34583634e-02,\n",
       "        -3.40761107e-03],\n",
       "       [-2.08710459e-02, -1.59919668e-01, -2.98320551e-02,\n",
       "         6.83082989e-02,  1.88742370e-01,  1.20551512e-01,\n",
       "         1.17477221e+00, -1.55881015e-01, -1.65341033e-01,\n",
       "         5.24484365e-02,  5.74727895e-02,  6.17245452e-02,\n",
       "        -7.23342627e-02, -1.09500277e-01,  1.26679439e-01,\n",
       "        -1.07010811e-01, -3.58787922e-02,  1.74705007e-01,\n",
       "         8.52743416e-03, -3.68353546e-02,  6.12815826e-02,\n",
       "        -1.28252918e-01, -8.29855947e-02, -6.97712183e-02,\n",
       "         4.75239053e-02],\n",
       "       [-4.38942366e-02, -4.38445646e-02, -5.04995151e-02,\n",
       "        -2.01252048e-04, -6.79248977e-02, -1.17115378e-02,\n",
       "        -1.00907374e-01,  9.49900400e-01, -5.40784307e-02,\n",
       "         1.15830325e-02,  8.13070123e-03,  1.04973969e-02,\n",
       "         7.04500516e-02, -2.97923011e-02,  8.55333457e-02,\n",
       "         3.92357335e-03, -8.77108060e-02, -5.93798063e-02,\n",
       "         4.17038611e-02, -3.46280217e-02, -3.65306975e-02,\n",
       "        -3.61938968e-02,  1.32988708e-02,  6.51589560e-02,\n",
       "        -8.58349168e-02],\n",
       "       [ 8.85220003e-02, -2.73677721e-03,  7.34648474e-02,\n",
       "        -1.26569767e-01,  3.67244531e-02, -1.00440229e-01,\n",
       "        -5.65549108e-02, -8.98477961e-02,  1.07175025e+00,\n",
       "        -3.50302673e-02,  4.33941000e-02, -1.86141135e-02,\n",
       "        -7.29609732e-02,  1.83657534e-02, -5.45883405e-02,\n",
       "        -8.58646058e-02,  9.97667514e-02, -1.83415449e-01,\n",
       "         9.59071689e-02,  2.95116969e-03,  9.00609230e-03,\n",
       "         1.36604312e-01, -3.67136896e-02, -1.21699285e-01,\n",
       "         7.69041259e-03],\n",
       "       [ 5.87697829e-03,  4.32379051e-02, -2.72668066e-02,\n",
       "         4.68479675e-03,  2.24375470e-02, -1.75537930e-01,\n",
       "        -1.23827574e-01,  1.30729947e-02,  1.48906806e-03,\n",
       "         1.06111726e+00,  3.85106219e-02,  2.20491808e-02,\n",
       "        -2.84080335e-02,  9.68659113e-02,  2.11062652e-03,\n",
       "        -3.65069666e-02, -1.41377467e-02, -9.72316927e-02,\n",
       "         1.42093757e-01,  1.95787227e-02,  2.38816231e-03,\n",
       "         4.98493743e-02,  3.67532306e-02, -1.11943630e-02,\n",
       "        -1.11540404e-01],\n",
       "       [-6.41068685e-02, -4.57956959e-03,  3.98827882e-02,\n",
       "        -9.33476362e-03, -7.11379599e-02,  1.53875641e-01,\n",
       "         1.58042158e-01, -5.38767458e-02, -1.09467208e-01,\n",
       "         3.21851535e-02,  1.01081398e+00,  4.88676252e-02,\n",
       "         1.27125444e-01, -4.70693304e-02,  1.02244308e-01,\n",
       "        -1.77245042e-02,  2.02384630e-02, -1.12567875e-01,\n",
       "        -1.06357503e-01,  2.57130178e-02, -5.46175285e-02,\n",
       "        -1.35727536e-01,  8.06285380e-02, -1.88748711e-02,\n",
       "         8.88186555e-02],\n",
       "       [ 1.41048118e-02,  6.67184428e-03,  6.63396966e-04,\n",
       "         3.95754095e-02, -4.08742047e-02,  8.17235334e-02,\n",
       "        -2.91326903e-03,  2.32535411e-02,  3.45218041e-02,\n",
       "        -1.99587478e-02, -1.45428724e-02,  9.79515920e-01,\n",
       "        -2.89534965e-02,  1.59681601e-02, -4.39973451e-02,\n",
       "         7.07170980e-02,  3.81055626e-02,  1.29268493e-02,\n",
       "        -2.85527095e-02,  1.27583882e-02, -3.14377171e-03,\n",
       "         6.52407530e-02, -2.79283887e-02,  5.19493982e-02,\n",
       "        -1.80676825e-02],\n",
       "       [ 4.04358864e-02,  3.24744261e-02,  4.85223522e-02,\n",
       "         2.90974515e-02,  7.10122532e-02, -7.10099868e-02,\n",
       "        -1.62721321e-01,  3.46428807e-02,  9.53317654e-02,\n",
       "        -3.93465469e-02,  2.61487174e-02, -4.36585642e-02,\n",
       "         1.03711965e+00, -1.44927973e-02, -1.04608742e-01,\n",
       "         1.11590439e-02,  5.95622027e-02, -1.15644162e-01,\n",
       "         4.56612626e-02, -3.24072901e-02,  8.88640119e-03,\n",
       "         1.21434274e-01, -2.37248197e-02, -3.32936166e-02,\n",
       "        -1.68537209e-01],\n",
       "       [-6.48778219e-02,  1.34598833e-01,  7.11794097e-02,\n",
       "         3.30441590e-02, -7.87414698e-02, -1.18019364e-01,\n",
       "         2.62749951e-02,  3.22929540e-04, -6.75930380e-02,\n",
       "        -2.61530073e-03,  3.39511674e-02,  5.37558639e-03,\n",
       "        -3.05336888e-02,  1.04319640e+00,  1.72019968e-02,\n",
       "        -4.19131944e-02, -6.64976911e-02, -2.68985413e-03,\n",
       "         1.46575676e-01,  4.52605784e-02, -4.08391587e-02,\n",
       "        -8.29700436e-02, -2.87332148e-02,  1.10450749e-01,\n",
       "         4.70513042e-02],\n",
       "       [-8.23080832e-02,  1.44918201e-01,  6.88768363e-02,\n",
       "        -4.53911612e-02, -1.87931732e-01,  4.83385699e-02,\n",
       "         1.02322407e-01,  1.44302004e-01,  2.93721771e-02,\n",
       "        -7.21184726e-02, -6.96862078e-02, -1.26126146e-02,\n",
       "        -7.70821422e-03, -4.21911732e-02,  1.01160469e+00,\n",
       "        -2.67546496e-02, -2.59307458e-01,  7.36443702e-02,\n",
       "        -1.46654138e-02,  1.72811058e-01,  1.65618714e-01,\n",
       "        -1.36573317e-01, -7.22536562e-02,  7.30124983e-03,\n",
       "         3.90819479e-02],\n",
       "       [-7.88476520e-03, -1.70364662e-02, -7.36484338e-02,\n",
       "        -1.02337644e-01,  3.27322439e-02, -9.91420292e-02,\n",
       "         3.67151286e-02,  1.52249845e-01, -1.08033866e-01,\n",
       "         3.57272582e-02,  2.29422496e-02, -1.79990147e-02,\n",
       "        -5.87321536e-02,  2.02465903e-02, -1.95181952e-02,\n",
       "         1.22786231e+00,  6.33542516e-04,  6.93852458e-03,\n",
       "         2.75563345e-03, -4.56821981e-02, -4.90775694e-02,\n",
       "        -1.14437926e-01,  1.22398895e-02,  1.75567982e-01,\n",
       "         1.48137808e-01],\n",
       "       [-5.60551127e-02, -1.18542447e-01,  2.41699326e-02,\n",
       "         1.42194325e-01,  4.42225357e-02,  8.76521205e-02,\n",
       "         6.83347542e-02, -2.89941052e-02, -8.51435800e-02,\n",
       "         3.49028873e-02,  3.43985439e-02, -2.98566856e-02,\n",
       "         3.75018229e-02,  1.59352101e-02, -4.20100149e-02,\n",
       "        -2.02350635e-02,  1.07636597e+00,  7.53680777e-02,\n",
       "        -7.05795444e-02,  8.98301873e-02,  6.27834832e-02,\n",
       "        -7.66606985e-02, -7.93765881e-02, -2.22315557e-02,\n",
       "        -1.67364027e-03],\n",
       "       [ 3.29220065e-02, -3.87827190e-02, -4.31050480e-02,\n",
       "         6.92777239e-02,  1.06026013e-01, -9.00375332e-02,\n",
       "        -4.64596079e-02, -4.27518390e-02,  1.26122230e-02,\n",
       "         3.06424221e-03, -2.03917925e-02, -9.39288683e-02,\n",
       "        -4.31088247e-02,  2.88953032e-02, -4.05890440e-02,\n",
       "         1.79406348e-01,  8.16551236e-02,  1.20033975e+00,\n",
       "         4.05971913e-02, -1.09957598e-01, -1.13027859e-02,\n",
       "         1.67002707e-02, -1.78069124e-02,  1.31557881e-01,\n",
       "         2.04964975e-02],\n",
       "       [-7.68011161e-02, -1.24213602e-01, -6.58703639e-02,\n",
       "        -1.84611643e-02, -3.52104242e-02,  8.01083237e-02,\n",
       "         5.03635042e-02,  8.52027619e-02, -4.87860638e-02,\n",
       "         6.10090406e-02,  4.61518368e-02,  1.63076024e-02,\n",
       "        -2.18205574e-02,  7.75853572e-02,  9.92055785e-02,\n",
       "         1.22139787e-01,  1.26497912e-01,  1.40464927e-02,\n",
       "         1.04773000e+00, -8.05058882e-02, -8.84284966e-02,\n",
       "         1.54277795e-02,  1.28694383e-03,  9.39066551e-02,\n",
       "        -2.01013113e-02],\n",
       "       [-6.37108168e-03,  5.72027311e-02, -3.62209618e-02,\n",
       "         2.21473176e-02, -4.96789006e-02, -6.18649224e-02,\n",
       "        -1.85300168e-03,  1.13886120e-01,  7.59922308e-02,\n",
       "        -2.08579510e-02, -7.71274787e-02,  1.14380080e-02,\n",
       "         7.71102389e-02,  4.51774525e-02, -9.38782460e-02,\n",
       "         5.03150592e-02, -5.53508598e-02,  7.27955945e-02,\n",
       "        -4.53758383e-02,  1.08392857e+00,  3.41627140e-02,\n",
       "        -1.06431063e-02, -2.46962639e-02, -2.59812259e-02,\n",
       "        -1.03977861e-01],\n",
       "       [-1.04071172e-01,  3.25591805e-02,  5.29021538e-02,\n",
       "        -5.59740185e-02, -7.18921781e-02,  2.18067396e-02,\n",
       "        -5.43570386e-02,  1.36954528e-01,  1.53701115e-02,\n",
       "         9.53413581e-02, -2.22604729e-02, -1.04963371e-01,\n",
       "         2.65364493e-02,  1.47456058e-01,  3.54592963e-02,\n",
       "         1.12414838e-02, -1.39020211e-02, -4.86556979e-03,\n",
       "        -1.07075352e-01,  2.88870073e-02,  1.02612351e+00,\n",
       "        -9.91428638e-02,  2.22622687e-02,  6.12916577e-02,\n",
       "        -1.58410491e-01],\n",
       "       [-4.81754809e-02,  3.18858843e-02,  5.16946011e-02,\n",
       "        -1.50495169e-01,  1.25819338e-01,  1.59379128e-01,\n",
       "        -6.30064563e-02, -5.96272291e-02, -6.35748388e-02,\n",
       "         5.90010402e-02, -1.87224014e-02, -1.97096843e-02,\n",
       "        -3.27912982e-02, -1.27048297e-01,  1.03492842e-01,\n",
       "        -1.05376883e-01,  2.34669805e-02, -1.00773242e-02,\n",
       "        -1.02930498e-02, -1.13225486e-01, -9.62964563e-02,\n",
       "         9.98016447e-01, -7.28149984e-03, -1.02943373e-01,\n",
       "        -1.35533402e-01],\n",
       "       [-4.67953691e-02,  5.63406869e-02, -7.93540405e-02,\n",
       "        -1.12311433e-01,  1.11683057e-02,  1.45113201e-01,\n",
       "         2.28034770e-02,  6.52023526e-02,  1.04787689e-01,\n",
       "         8.75150609e-02,  5.77541789e-02, -4.04234187e-02,\n",
       "        -5.93875267e-02,  8.20992020e-02,  2.93231584e-02,\n",
       "        -1.00776919e-01, -1.15023151e-02,  1.57649812e-01,\n",
       "        -1.16045239e-01,  4.33553703e-02, -6.96838719e-02,\n",
       "        -2.04324797e-01,  1.08118533e+00, -8.13788114e-03,\n",
       "         4.28736702e-02],\n",
       "       [ 8.28809611e-03, -5.13233503e-03, -2.31646948e-02,\n",
       "        -3.19821160e-03,  5.71268771e-02, -2.87282402e-02,\n",
       "        -3.50623477e-03, -2.98542823e-02, -1.14493788e-02,\n",
       "        -5.43082914e-02, -1.22151789e-02,  2.74649310e-02,\n",
       "         1.45593930e-02, -1.92024084e-02, -2.36279922e-02,\n",
       "        -1.37144724e-02, -5.02519020e-02,  7.23543069e-02,\n",
       "         3.06480824e-02,  2.08403313e-02,  5.19284540e-02,\n",
       "        -2.05074859e-02, -1.02743133e-03,  9.96051984e-01,\n",
       "        -6.07265688e-04],\n",
       "       [-8.63687244e-02,  5.98604508e-02, -8.16981389e-03,\n",
       "        -3.53261042e-02, -1.17224679e-01,  4.43164991e-02,\n",
       "        -2.31428559e-02,  1.71318077e-01, -2.57577363e-02,\n",
       "         6.15634469e-02, -8.90290254e-03, -1.02775406e-01,\n",
       "         4.86063534e-02,  5.42201337e-02,  4.26458853e-02,\n",
       "         1.10500569e-01,  2.60395699e-02, -2.57766453e-02,\n",
       "        -6.57707618e-02, -6.28942533e-02, -1.74688896e-02,\n",
       "        -6.86027253e-02,  3.30532026e-02,  7.21675291e-02,\n",
       "         1.03136555e+00]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.layers[1].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.01020408163265306, 0.02040816326530612, 0.030612244897959183, 0.04081632653061224, 0.0510204081632653, 0.061224489795918366, 0.07142857142857142, 0.08163265306122448, 0.09183673469387754, 0.1020408163265306, 0.11224489795918366, 0.12244897959183673, 0.13265306122448978, 0.14285714285714285, 0.1530612244897959, 0.16326530612244897, 0.17346938775510204, 0.18367346938775508, 0.19387755102040816, 0.2040816326530612, 0.21428571428571427, 0.22448979591836732, 0.2346938775510204, 0.24489795918367346, 0.25510204081632654, 0.26530612244897955, 0.2755102040816326, 0.2857142857142857, 0.29591836734693877, 0.3061224489795918, 0.31632653061224486, 0.32653061224489793, 0.336734693877551, 0.3469387755102041, 0.3571428571428571, 0.36734693877551017, 0.37755102040816324, 0.3877551020408163, 0.39795918367346933, 0.4081632653061224, 0.4183673469387755, 0.42857142857142855, 0.4387755102040816, 0.44897959183673464, 0.4591836734693877, 0.4693877551020408, 0.47959183673469385, 0.4897959183673469, 0.5, 0.0, 0.01020408163265306, 0.02040816326530612, 0.030612244897959183, 0.04081632653061224, 0.0510204081632653, 0.061224489795918366, 0.07142857142857142, 0.08163265306122448, 0.09183673469387754, 0.1020408163265306, 0.11224489795918366, 0.12244897959183673, 0.13265306122448978, 0.14285714285714285, 0.1530612244897959, 0.16326530612244897, 0.17346938775510204, 0.18367346938775508, 0.19387755102040816, 0.2040816326530612, 0.21428571428571427, 0.22448979591836732, 0.2346938775510204, 0.24489795918367346, 0.25510204081632654, 0.26530612244897955, 0.2755102040816326, 0.2857142857142857, 0.29591836734693877, 0.3061224489795918, 0.31632653061224486, 0.32653061224489793, 0.336734693877551, 0.3469387755102041, 0.3571428571428571, 0.36734693877551017, 0.37755102040816324, 0.3877551020408163, 0.39795918367346933, 0.4081632653061224, 0.4183673469387755, 0.42857142857142855, 0.4387755102040816, 0.44897959183673464, 0.4591836734693877, 0.4693877551020408, 0.47959183673469385, 0.4897959183673469, 0.5]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 1.46024854 2.81072014 0.         0.         0.         3.88601831\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         6.57958053 0.\n",
      " 0.         0.         0.         0.         0.         1.27789766\n",
      " 0.         0.         1.02883416 0.         0.         0.\n",
      " 2.36960135 0.         0.         0.         0.         1.48878519\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         1.24779715 0.\n",
      " 0.         0.         0.         0.         0.         2.89321097\n",
      " 0.         0.         0.         0.         1.84278837 1.06910978\n",
      " 3.45406997 3.09459815 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         1.08833282 1.9443363  0.         2.91250711 0.\n",
      " 0.         0.         2.08767768 0.        ]\n",
      "[ 6.47968142e+00 -1.07347401e+00  7.18993862e-01 -1.03098276e+00\n",
      "  6.62705593e-01  6.18552390e-01  1.74276739e+00  3.47700988e-01\n",
      "  1.59467717e+00  2.75215026e-01  9.94187897e-01 -4.17959608e-02\n",
      " -7.59590248e-01  1.45154405e-01 -8.56575549e-01 -1.41357472e+00\n",
      " -1.43164913e+00 -1.83837988e+00 -2.27064772e+00 -2.69831070e-02\n",
      "  1.06264496e+00  8.74185956e-01 -4.03978935e-01  1.87958496e+00\n",
      "  5.81955717e-01  2.51337540e-01 -5.97872660e-01 -6.40866032e-01\n",
      " -6.44889506e-01  1.05599514e+00 -4.83764737e-01 -7.33371727e-01\n",
      "  2.15245741e-01 -5.76798880e-01  1.52272040e-01  2.31232854e+00\n",
      "  1.05097834e+00  6.24310734e-01  4.84786344e-01 -4.80231473e-01\n",
      "  9.77644041e-01  8.12840316e-01  3.26113059e+00 -1.26984256e+00\n",
      " -8.36656877e-01 -9.07935030e-01 -9.70463096e-01  1.78477253e-01\n",
      " -1.20472973e+00 -1.83960433e-01 -5.62208774e-01 -1.92143589e-01\n",
      "  7.78061027e-01 -9.59055729e-01 -1.75653412e+00  4.53300056e-01\n",
      " -2.22754353e+00 -7.39122809e-01 -9.24909484e-01  1.62871073e+00\n",
      " -1.14949978e+00 -8.33065090e-01 -1.03599858e+00  1.15013706e-01\n",
      "  6.05360104e-01  2.19258528e+00  6.83390152e-01  1.21941071e+00\n",
      "  3.47169795e-01 -5.09812777e-01  4.85355121e-03 -5.42632757e-01\n",
      " -1.11179664e+00  1.93487451e+00  6.96090934e-02  9.75208004e-01\n",
      " -2.29776368e+00 -2.10526559e+00  6.19034850e-01 -1.64996465e+00\n",
      "  3.20492884e-01 -2.49981370e+00 -1.35081394e+00  1.16097862e+00\n",
      "  1.24162283e+00 -1.89506314e-01 -2.01499728e+00  2.64881173e-01\n",
      " -1.15824098e+00  6.42066092e-01  1.05864986e+00 -2.61589955e-01\n",
      " -1.67841204e+00 -9.59644511e-02 -6.71391641e-01 -6.91041593e-01\n",
      " -6.35141810e-01  1.67704303e+00 -5.24093250e-02  6.14353421e-02]\n",
      "-2.1874485829025665\n"
     ]
    }
   ],
   "source": [
    "dataIn = 2*list(np.linspace(0,0.5,50))\n",
    "dataOut = dataIn\n",
    "\n",
    "nn.inputData(dataIn, dataOut)\n",
    "\n",
    "nn.updateActivations()\n",
    "out = nn.layers[-1].getActivations()\n",
    "\n",
    "print(dataOut)\n",
    "print(out)\n",
    "print(nn.layers[-1].weights[0])\n",
    "print(np.dot(nn.layers[-1].weights[0], dataIn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAST LAYER\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "gradientDescentWeights() missing 1 required positional argument: 'layer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-8fece5931a9c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LAST LAYER\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mNN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradientDescentWeights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m#NN.updateDesiredActivationsUp(nn.layers[-1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#NN.gradientDescentBiases(nn.layers[-1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: gradientDescentWeights() missing 1 required positional argument: 'layer'"
     ]
    }
   ],
   "source": [
    "dataIn = [1, 1]*50\n",
    "dataOut = dataIn\n",
    "nn.inputData(dataIn, dataOut)\n",
    "\n",
    "print(\"LAST LAYER\")\n",
    "NN.gradientDescentWeights(nn.layers[-1])\n",
    "#NN.updateDesiredActivationsUp(nn.layers[-1])\n",
    "#NN.gradientDescentBiases(nn.layers[-1])\n",
    "\n",
    "nn.updateActivations()\n",
    "nn.showActivations()\n",
    "print(\"cost: %s\" % nn.getCost())\n",
    "\n",
    "dataIn = [1, 0]*50\n",
    "dataOut = dataIn\n",
    "nn.inputData(dataIn, dataOut)\n",
    "\n",
    "print(\"LAST LAYER\")\n",
    "NN.gradientDescentWeights(nn.layers[-1])\n",
    "#NN.updateDesiredActivationsUp(nn.layers[-1])\n",
    "#NN.gradientDescentBiases(nn.layers[-1])\n",
    "\n",
    "nn.updateActivations()\n",
    "nn.showActivations()\n",
    "print(\"cost: %s\" % nn.getCost())\n",
    "\n",
    "dataIn = [0, 1]*50\n",
    "dataOut = dataIn\n",
    "nn.inputData(dataIn, dataOut)\n",
    "\n",
    "print(\"LAST LAYER\")\n",
    "NN.gradientDescentWeights(nn.layers[-1])\n",
    "#NN.updateDesiredActivationsUp(nn.layers[-1])\n",
    "#NN.gradientDescentBiases(nn.layers[-1])\n",
    "\n",
    "nn.updateActivations()\n",
    "nn.showActivations()\n",
    "print(\"cost: %s\" % nn.getCost())\n",
    "\n",
    "dataIn = [0, 0]*50\n",
    "dataOut = dataIn\n",
    "nn.inputData(dataIn, dataOut)\n",
    "\n",
    "print(\"LAST LAYER\")\n",
    "NN.gradientDescentWeights(nn.layers[-1])\n",
    "#NN.updateDesiredActivationsUp(nn.layers[-1])\n",
    "#NN.gradientDescentBiases(nn.layers[-1])\n",
    "\n",
    "nn.updateActivations()\n",
    "nn.showActivations()\n",
    "print(\"cost: %s\" % nn.getCost())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
