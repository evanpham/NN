{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting details on weight initialization https://pouannes.github.io/blog/initialization/\n",
    "\n",
    "Use Kaiming method \n",
    "\n",
    "\"The Kaiming paper accordingly suggests to initialize the weights of layer l with a zero-mean Gaussian distribution with a standard deviation of sqrt(s/Nl) , and null biases.\"\n",
    "\n",
    "Nl is the number of neurons in layer l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(number):\n",
    "    \"\"\"\n",
    "    Returns the ReLU of a number\n",
    "    ReLU function is 0 for all negative inputs, and f(x) = x for all x >= 0\n",
    "    \"\"\"\n",
    "    return max(0, number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    \"\"\"\n",
    "    Neuron class for neural network\n",
    "    Each neuron is a node in the network\n",
    "    Can be organized into layers with Layer class\n",
    "    Each Neuron has a list of Neurons coming in (the upstream neurons in the network)\n",
    "    and a list of Neurons going out (the downstream neurons in the network)\n",
    "    The weights correspond to the list of input Neurons\n",
    "    ex. a Neuron with 5 upstream neurons will have 5 weights, one for each input\n",
    "    Bias determines a Neurons tendency to be off/on\n",
    "    \"\"\"\n",
    "    def __init__(self, activation=0, inNeurons=[], outNeurons=[], weights=[], bias=0):\n",
    "        \"\"\"\n",
    "        Constructor for Neuron class\n",
    "        \"\"\"\n",
    "        self.inNeurons = inNeurons\n",
    "        self.outNeurons = outNeurons\n",
    "        self.activation = activation\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "        \n",
    "    def addIn(self, n, weight):\n",
    "        \"\"\"\n",
    "        Adds input neuron with provided weight\n",
    "        Used in Layer class to connect Layers\n",
    "        \"\"\"\n",
    "        self.inNeurons.append(n)\n",
    "        self.weights.append(weight)\n",
    "        \n",
    "    def addOut(self, neuron):\n",
    "        \"\"\"\n",
    "        Adds output neuron\n",
    "        Used in Layer class to connect Layers\n",
    "        \"\"\"\n",
    "        self.outNeurons.append(neuron)\n",
    "    \n",
    "    def getActivation(self):\n",
    "        \"\"\"\n",
    "        Returns activation of Neuron\n",
    "        \"\"\"\n",
    "        return self.activation\n",
    "    \n",
    "    def setActivation(self, a):\n",
    "        \"\"\"\n",
    "        Sets activation of Neuron to a\n",
    "        Returns a\n",
    "        \"\"\"\n",
    "        self.activation = a\n",
    "        return a\n",
    "    \n",
    "    def getBias(self):\n",
    "        \"\"\"\n",
    "        Returns bias of Neuron\n",
    "        \"\"\"\n",
    "        return self.bias\n",
    "    \n",
    "    def setBias(self, b):\n",
    "        \"\"\"\n",
    "        Sets bias of Neuron to b\n",
    "        Returns b\n",
    "        \"\"\"\n",
    "        self.bias = b\n",
    "        return b\n",
    "\n",
    "\n",
    "class Layer:\n",
    "    \"\"\"\n",
    "    Layer class for neural network\n",
    "    Layers are collections of neurons\n",
    "    Layers can be linked together to form networks\n",
    "    \"\"\"\n",
    "    def __init__(self, neurons=[], generate=True, size=0):\n",
    "        \"\"\"\n",
    "        Constructor for Layer class\n",
    "        Can input a list of neurons to build layer, or randomly generate\n",
    "        neurons for layer of desired size\n",
    "        \"\"\"\n",
    "        self.neurons = neurons.copy()\n",
    "        print(\"Initializing Layer\")\n",
    "        \n",
    "        #  Generates the neurons for the layer\n",
    "        if generate and len(self.neurons) == 0:\n",
    "            for i in range(size):\n",
    "                self.neurons.append(Neuron())\n",
    "        \n",
    "        print(\"Created layer of size %d\" % len(self.neurons))\n",
    "        \n",
    "        #  Initializes attributes\n",
    "        self.size = size\n",
    "        self.upLayer = None\n",
    "        self.downLayer = None\n",
    "        self.weights = None\n",
    "        self.weightsSet = False\n",
    "        \n",
    "        #  Records activations and biases of neurons in layer\n",
    "        self.biases = np.array(list(map(Neuron.getBias, self.neurons)))\n",
    "        self.activations = np.array(list(map(Neuron.getActivation, self.neurons)))\n",
    "    \n",
    "    def setActivations(self, actList):\n",
    "        \"\"\"\n",
    "        Sets activations of neurons in layer to actList\n",
    "        \"\"\"\n",
    "        #  Checks to ensure provided activation list is the appropriate size\n",
    "        if len(actList) == self.size:\n",
    "            for i in range(self.size):\n",
    "                self.neurons[i].setActivation(actList[i])\n",
    "            self.activations = actList\n",
    "        else:\n",
    "            raise Exception(\"Invalid activation list length\")\n",
    "                \n",
    "    \n",
    "    def getActivations(self):\n",
    "        \"\"\"\n",
    "        Returns activations of Neurons in Layer\n",
    "        \"\"\"\n",
    "        return self.activations\n",
    "    \n",
    "    def getBiases(self):\n",
    "        \"\"\"\n",
    "        Returns biases of Neurons in Layer\n",
    "        \"\"\"\n",
    "        return self.biases\n",
    "    \n",
    "    def getSize(self):\n",
    "        \"\"\"\n",
    "        Returns number of Neurons in Layer\n",
    "        \"\"\"\n",
    "        return self.size\n",
    "    \n",
    "    def downstreamConnect(self, down, weights=None):\n",
    "        \"\"\"\n",
    "        Connects neuron layer \"down\" to self \n",
    "        Connection is such that \"down\" is downstream in the neural network\n",
    "        Unless specified, weight matrix is initialized randomly within Kaiming distribution\n",
    "        layer1.upstreamConnect(layer2) is equivalent to layer2.downstreamConnect(layer1)\n",
    "        IMPORTANT NOTE: WEIGHT MATRIX MIGHT NOT PROPERLY FOLLOW KAIMING\n",
    "        INSTEAD THEY SAMPLE RANDOMLY FROM A GAUSSIAN DISTRIBUTION WITH VARIANCE DETERMINED BY KAIMING\n",
    "        MAY CAUSE PROBLEMS WITH SMALL LAYERS, POSSIBLY NEEDS FIX LATER\n",
    "        \"\"\"\n",
    "        upLayerNeurons = self.neurons\n",
    "        downLayerNeurons = down.neurons\n",
    "        \n",
    "        if not weights:\n",
    "            #  Create random weight initialization matrix\n",
    "            #  Weights are picked randomly from gaussian of mean=0 and variance according to Kaiming\n",
    "            weightVariance = np.sqrt(2/len(upLayerNeurons))\n",
    "            weights = np.random.normal(scale=weightVariance, size=(down.getSize(), self.getSize()))\n",
    "            print(\"Created %d by %d weight matrix\" % weights.shape)\n",
    "            down.weightsSet = True\n",
    "            \n",
    "        for d in range(down.getSize()):\n",
    "            for u in range(self.getSize()):\n",
    "                #  Connect all Neurons between the Layers\n",
    "                #  Set weights of Neurons in downstream Layer\n",
    "                upLayerNeurons[u].addOut(downLayerNeurons[d])\n",
    "                downLayerNeurons[d].addIn(upLayerNeurons[u], weights[d, u])\n",
    "        \n",
    "        #  Set weight matrix of downstream Layer and mark up/downstream connections\n",
    "        down.weights = weights  #  This should be a method like updateWeights(), might be useful later\n",
    "        down.upLayer = self\n",
    "        self.downLayer = l\n",
    "        \n",
    "        return weights\n",
    "    \n",
    "    def upstreamConnect(self, up):\n",
    "        \"\"\"\n",
    "        IMPLEMENTATION INCOMPLETE\n",
    "        Connects neuron layer \"up\" to self \n",
    "        Connection is such that \"up\" is upstream in the neural network\n",
    "        layer1.upstreamConnect(layer2) is equivalent to layer2.downstreamConnect(layer1)\n",
    "        \"\"\"\n",
    "    \n",
    "    def update(self):\n",
    "        \"\"\"\n",
    "        Updates Neuron activations based on weight matrix, biases and activations of upstream Layer\n",
    "        \"\"\"\n",
    "        #  Only update if weights had been set\n",
    "        if self.weightsSet:\n",
    "            weightedSum = np.matmul(self.weights, self.upLayer.getActivations())\n",
    "            weightedSum = np.subtract(weightedSum, self.biases)\n",
    "            newActivations = np.array(list(map(relu, weightedSum)))\n",
    "            self.setActivations(newActivations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "    \"\"\"\n",
    "    Neural Network class\n",
    "    A NN consists of Neuron Layers, connected in a linear manner\n",
    "    End Layers act as data input and output\n",
    "    Middle Layers each have upstream and downstream connections\n",
    "    and serve as NN's hidden Layers\n",
    "    \"\"\"\n",
    "    def __init__(self, numLayers, layerSizes):\n",
    "        \"\"\"\n",
    "        Constructor for NN class\n",
    "        numLayers is an integer that determines the number of Layers in the NN\n",
    "        layerSizes is a list or tuple of length numLayers that determines the\n",
    "        number of Neurons in each layer, with layerSizes[0] being the size of the input layer\n",
    "        \"\"\"\n",
    "        self.numLayers = numLayers\n",
    "        self.layerSizes = layerSizes\n",
    "        print(\"Creating Neural Network with %d layers\" % numLayers)\n",
    "        self.layers = []\n",
    "        \n",
    "        #  Create layers and connect them\n",
    "        for i in range(numLayers):\n",
    "            self.layers.append(Layer(size=layerSizes[i]))\n",
    "            if i > 0:\n",
    "                #  No downstream connection for the last layer\n",
    "                self.layers[i-1].downstreamConnect(self.layers[i])\n",
    "        print(\"Neural Network Initialized\")\n",
    "        \n",
    "    def inputData(self, data):\n",
    "        \"\"\"\n",
    "        Sets input layer activations to data if data is the proper size\n",
    "        Otherwise raises Exception\n",
    "        \"\"\"\n",
    "        if self.layers[0].getSize() == len(data):\n",
    "            self.layers[0].setActivations(data)\n",
    "        else:\n",
    "            raise Exception(\"Invalid data size\")\n",
    "    \n",
    "    def showStructure(self):\n",
    "        \"\"\"\n",
    "        Prints out the number of layers in the NN\n",
    "        Prints out the sizes of each layer\n",
    "        \"\"\"\n",
    "        print(\"The network is contains %d layers\" % numLayers)\n",
    "        print(\"The layer sizes are %s\" % layerSizes)\n",
    "        \n",
    "    def update(self):\n",
    "        \"\"\"\n",
    "        Updates all layers in NN according to their weight matrix and the activations\n",
    "        of their upstream Layer\n",
    "        \"\"\"\n",
    "        #  Input layer is skipped, as it has no upstream layer\n",
    "        for layer in self.layers[1:]:\n",
    "            layer.update()\n",
    "            \n",
    "    def showActivations(self):\n",
    "        \"\"\"\n",
    "        Displays activations of each Layer of the NN\n",
    "        \"\"\"\n",
    "        for i in range(10):\n",
    "            print(self.layers[i].getActivations())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Layer\n",
      "Created layer of size 10\n",
      "layer1 activations: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Initializing Layer\n",
      "Created layer of size 5\n",
      "Created 5 by 10 weight matrix\n",
      "None\n",
      "[[ 0.41826406 -0.73508648 -0.91252122 -0.55303445 -0.44873905 -0.2083074\n",
      "   0.78527366  0.93844238  0.78887115  0.92341751]\n",
      " [-0.00826183  0.42273283 -0.14165828 -0.08958547 -0.18177151 -0.26046132\n",
      "   0.31217827 -0.34199467  0.63927707  0.23725629]\n",
      " [ 0.33466217  0.30406361 -0.3573735  -0.36564607 -0.70257798 -0.15948072\n",
      "   0.46747935  0.1833991  -0.37148799 -0.29806492]\n",
      " [-0.50984699 -0.53992274  0.05835959  0.06526827 -0.65753727 -0.68765525\n",
      "  -0.38695866 -0.152884    0.90457353 -0.53596613]\n",
      " [-0.28145428  0.10075495  0.08126343 -0.57253182 -0.21441242 -0.06520552\n",
      "  -0.85161343 -0.32746237 -0.16212719  0.71408536]]\n",
      "layer2 activations: [0 0 0 0 0]\n",
      "layer2 activations: [18.84673994  4.56989734  0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "layer1 = Layer(size=10)\n",
    "layer1.setActivations(list(range(10)))\n",
    "print(\"layer1 activations: %s\" % layer1.activations)\n",
    "layer2 = Layer(size=5)\n",
    "\n",
    "w = layer1.downstreamConnect(layer2)\n",
    "print(layer1.weights)\n",
    "print(layer2.weights)\n",
    "print(\"layer2 activations: %s\" % layer2.activations)\n",
    "layer2.update()\n",
    "print(\"layer2 activations: %s\" % layer2.activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Neural Network with 10 layers\n",
      "Initializing Layer\n",
      "Created layer of size 10\n",
      "Initializing Layer\n",
      "Created layer of size 10\n",
      "Created 10 by 10 weight matrix\n",
      "Initializing Layer\n",
      "Created layer of size 10\n",
      "Created 10 by 10 weight matrix\n",
      "Initializing Layer\n",
      "Created layer of size 10\n",
      "Created 10 by 10 weight matrix\n",
      "Initializing Layer\n",
      "Created layer of size 10\n",
      "Created 10 by 10 weight matrix\n",
      "Initializing Layer\n",
      "Created layer of size 10\n",
      "Created 10 by 10 weight matrix\n",
      "Initializing Layer\n",
      "Created layer of size 10\n",
      "Created 10 by 10 weight matrix\n",
      "Initializing Layer\n",
      "Created layer of size 10\n",
      "Created 10 by 10 weight matrix\n",
      "Initializing Layer\n",
      "Created layer of size 10\n",
      "Created 10 by 10 weight matrix\n",
      "Initializing Layer\n",
      "Created layer of size 10\n",
      "Created 10 by 10 weight matrix\n",
      "Neural Network Initialized\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "[2.16074854 0.         1.30372529 0.         0.         2.16798594\n",
      " 0.         1.38733713 2.27788211 2.13955983]\n",
      "[0.         1.75736968 0.48511593 2.64337027 0.         0.\n",
      " 0.         0.         1.89263538 2.70618942]\n",
      "[1.19189235 0.67997343 0.36953626 2.54178379 0.         0.\n",
      " 0.         0.05125253 0.6155403  0.        ]\n",
      "[0.         0.         0.         0.         0.30280962 1.08872388\n",
      " 0.         1.0909157  0.54582049 0.        ]\n",
      "[0.44240473 0.         0.         1.34454712 0.29345364 0.04857816\n",
      " 0.         0.         0.09117737 0.74079556]\n",
      "[0.21866696 0.41418747 0.         0.53644015 0.3458255  0.\n",
      " 0.         0.         0.6180332  0.08117986]\n",
      "[0.44343846 0.23512822 0.18946578 0.         0.         0.\n",
      " 0.         0.11229521 0.20061571 0.        ]\n",
      "[0.         0.06334323 0.         0.         0.06682058 0.0853485\n",
      " 0.         0.         0.25051594 0.        ]\n",
      "[0.07981816 0.17196868 0.01963763 0.14122118 0.         0.01378641\n",
      " 0.         0.         0.02464499 0.        ]\n"
     ]
    }
   ],
   "source": [
    "nn = NN(10, [10]*10)\n",
    "data = [2]*10\n",
    "nn.inputData(data)\n",
    "nn.showActivations()\n",
    "nn.update()\n",
    "nn.showActivations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
